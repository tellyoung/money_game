{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0f3a7e",
   "metadata": {
    "id": "ef0f3a7e"
   },
   "source": [
    "## Quantitative trading in China A stock market with FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0bfb2",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/3-Practical/FinRL_China_A_Share_Market.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GiOWTM8RRG_n",
   "metadata": {
    "id": "GiOWTM8RRG_n"
   },
   "source": [
    "Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Q8gKimq2PZDh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:47:50.776993Z",
     "iopub.status.busy": "2025-04-12T03:47:50.776216Z",
     "iopub.status.idle": "2025-04-12T03:47:50.782483Z",
     "shell.execute_reply": "2025-04-12T03:47:50.781679Z",
     "shell.execute_reply.started": "2025-04-12T03:47:50.776954Z"
    },
    "id": "Q8gKimq2PZDh",
    "outputId": "edf4ed40-5f02-4b93-b281-9cab1a02aae1"
   },
   "outputs": [],
   "source": [
    "# !pip install wrds\n",
    "# !pip install swig\n",
    "# !pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tmt2578_RI2-",
   "metadata": {
    "id": "tmt2578_RI2-"
   },
   "source": [
    "Install other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zDejJbjYQuUi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:47:51.340175Z",
     "iopub.status.busy": "2025-04-12T03:47:51.339303Z",
     "iopub.status.idle": "2025-04-12T03:47:51.344512Z",
     "shell.execute_reply": "2025-04-12T03:47:51.343780Z",
     "shell.execute_reply.started": "2025-04-12T03:47:51.340096Z"
    },
    "id": "zDejJbjYQuUi",
    "outputId": "6ec3f890-81d5-4164-be35-42f41da69828"
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install tushare\n",
    "#install talib\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') \n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "H0-reEAYJTkU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:47:51.854443Z",
     "iopub.status.busy": "2025-04-12T03:47:51.853547Z",
     "iopub.status.idle": "2025-04-12T03:47:51.862177Z",
     "shell.execute_reply": "2025-04-12T03:47:51.861648Z",
     "shell.execute_reply.started": "2025-04-12T03:47:51.854414Z"
    },
    "id": "H0-reEAYJTkU",
    "outputId": "7ba63085-8ea5-4c01-ab16-1b34de4e7fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yutieyang/Documents/yuty/yuty_projects/money_game/RL/FinRL-Meta\n"
     ]
    }
   ],
   "source": [
    "# %cd /\n",
    "# !git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "# %cd /FinRL-Meta/\n",
    "%cd /Users/yutieyang/Documents/yuty/yuty_projects/money_game/RL/FinRL-Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac7297",
   "metadata": {
    "id": "42ac7297"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-taylor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:48:09.150388Z",
     "iopub.status.busy": "2025-04-12T03:48:09.149437Z",
     "iopub.status.idle": "2025-04-12T03:48:10.689753Z",
     "shell.execute_reply": "2025-04-12T03:48:10.689493Z",
     "shell.execute_reply.started": "2025-04-12T03:48:09.150348Z"
    },
    "id": "fluid-taylor",
    "outputId": "30383d78-b504-4216-e338-addc1689c3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "# from IPython import display\n",
    "import IPython.display\n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "IPython.display.set_matplotlib_formats = set_matplotlib_formats\n",
    "IPython.display.set_matplotlib_formats(\"svg\")\n",
    "# display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config\n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv\n",
    "from agents.stablebaselines3_models import DRLAgent\n",
    "pd.options.display.max_columns = None\n",
    "    \n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb601f4a",
   "metadata": {
    "id": "eb601f4a"
   },
   "source": [
    "### Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c4ae89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T03:48:10.690492Z",
     "iopub.status.busy": "2025-04-12T03:48:10.690325Z",
     "iopub.status.idle": "2025-04-12T03:48:10.979955Z",
     "shell.execute_reply": "2025-04-12T03:48:10.979298Z",
     "shell.execute_reply.started": "2025-04-12T03:48:10.690483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yutieyang/Documents/yuty/yuty_projects/money_game/RL/FinRL-Meta\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339ab411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T03:50:19.082107Z",
     "iopub.status.busy": "2025-04-12T03:50:19.081562Z",
     "iopub.status.idle": "2025-04-12T03:50:19.086904Z",
     "shell.execute_reply": "2025-04-12T03:50:19.085771Z",
     "shell.execute_reply.started": "2025-04-12T03:50:19.082077Z"
    },
    "id": "339ab411"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/Users/yutieyang/Documents/yuty/yuty_projects/money_game/Data\"\n",
    "# if not os.path.exists(\"./datasets\" ):\n",
    "#     os.makedirs(\"./datasets\" )\n",
    "# if not os.path.exists(\"./trained_models\"):\n",
    "#     os.makedirs(\"./trained_models\" )\n",
    "# if not os.path.exists(\"./tensorboard_log\"):\n",
    "#     os.makedirs(\"./tensorboard_log\" )\n",
    "# if not os.path.exists(\"./results\" ):\n",
    "#     os.makedirs(\"./results\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad0a26",
   "metadata": {
    "id": "74ad0a26"
   },
   "source": [
    "### Download data, cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "transsexual-crack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T03:52:32.084513Z",
     "iopub.status.busy": "2025-04-12T03:52:32.083761Z",
     "iopub.status.idle": "2025-04-12T03:52:32.089948Z",
     "shell.execute_reply": "2025-04-12T03:52:32.088923Z",
     "shell.execute_reply.started": "2025-04-12T03:52:32.084483Z"
    },
    "id": "transsexual-crack"
   },
   "outputs": [],
   "source": [
    "ticket_list=['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH',\n",
    "       '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH',\n",
    "       '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
    "\n",
    "train_start_date='2015-01-01'\n",
    "train_stop_date='2019-08-01'\n",
    "\n",
    "val_start_date='2019-08-01'\n",
    "val_stop_date='2021-01-01'\n",
    "\n",
    "token='27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "preceding-selling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:07.309189Z",
     "iopub.status.busy": "2025-04-12T03:55:07.308641Z",
     "iopub.status.idle": "2025-04-12T03:55:15.551021Z",
     "shell.execute_reply": "2025-04-12T03:55:15.550758Z",
     "shell.execute_reply.started": "2025-04-12T03:55:07.309162Z"
    },
    "id": "preceding-selling",
    "outputId": "8b88552b-da4a-476f-d3a4-8ea79019819e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:08<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete! Dataset saved to /Users/yutieyang/Documents/yuty/yuty_projects/money_game/Data/RL/15A_20150101_20210101.csv. \n",
      "Shape of DataFrame: (21574, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download and clean\n",
    "ts_processor = Tushare(data_source=\"tushare\", \n",
    "                                   start_date=train_start_date,\n",
    "                                   end_date=val_stop_date,\n",
    "                                   time_interval=\"1d\",\n",
    "                                   token=token)\n",
    "ts_processor.download_data(ticker_list=ticket_list, save_path=os.path.join(data_path, \"RL/15A_20150101_20210101.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "X-xuvxev2sge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:16.253676Z",
     "iopub.status.busy": "2025-04-12T03:55:16.252850Z",
     "iopub.status.idle": "2025-04-12T03:55:16.326377Z",
     "shell.execute_reply": "2025-04-12T03:55:16.326099Z",
     "shell.execute_reply.started": "2025-04-12T03:55:16.253644Z"
    },
    "id": "X-xuvxev2sge",
    "outputId": "e198dad9-84ef-455f-d949-d45b30081392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (21930, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>15.88</td>\n",
       "      <td>16.25</td>\n",
       "      <td>15.56</td>\n",
       "      <td>16.07</td>\n",
       "      <td>16.07</td>\n",
       "      <td>5135687.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>19.82</td>\n",
       "      <td>20.91</td>\n",
       "      <td>19.82</td>\n",
       "      <td>20.53</td>\n",
       "      <td>20.53</td>\n",
       "      <td>371485.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>10.87</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.78</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9138873.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>6.59</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.45</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.14</td>\n",
       "      <td>11864996.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>33.90</td>\n",
       "      <td>35.25</td>\n",
       "      <td>33.01</td>\n",
       "      <td>34.66</td>\n",
       "      <td>34.66</td>\n",
       "      <td>6986272.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-05  15.88  16.25  15.56  16.07           16.07   \n",
       "1  600009.SH  2015-01-05  19.82  20.91  19.82  20.53           20.53   \n",
       "2  600016.SH  2015-01-05  10.87  10.96  10.50  10.78           10.78   \n",
       "3  600028.SH  2015-01-05   6.59   7.14   6.45   7.14            7.14   \n",
       "4  600030.SH  2015-01-05  33.90  35.25  33.01  34.66           34.66   \n",
       "\n",
       "        volume  \n",
       "0   5135687.09  \n",
       "1    371485.54  \n",
       "2   9138873.70  \n",
       "3  11864996.45  \n",
       "4   6986272.15  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_processor.clean_data()\n",
    "ts_processor.fillna()\n",
    "ts_processor.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e40b006",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:16.872081Z",
     "iopub.status.busy": "2025-04-12T03:55:16.871303Z",
     "iopub.status.idle": "2025-04-12T03:55:18.507460Z",
     "shell.execute_reply": "2025-04-12T03:55:18.507185Z",
     "shell.execute_reply.started": "2025-04-12T03:55:16.872040Z"
    },
    "id": "3e40b006",
    "outputId": "86eb6231-2bfa-4f04-bd37-9296d88102d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (21885, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "1  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "2  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "3  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "4  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "1   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "2  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "3  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "4  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "1  100.000000       20.2000       20.2000  \n",
       "2  100.000000       10.4775       10.4775  \n",
       "3   64.934862        7.0425        7.0425  \n",
       "4  100.000000       35.1925       35.1925  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_technical_indicator\n",
    "ts_processor.add_technical_indicator(config.INDICATORS)\n",
    "ts_processor.fillna()\n",
    "ts_processor.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc2e45",
   "metadata": {
    "id": "25fc2e45"
   },
   "source": [
    "### Split traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pending-mother",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:18.508219Z",
     "iopub.status.busy": "2025-04-12T03:55:18.508137Z",
     "iopub.status.idle": "2025-04-12T03:55:18.515981Z",
     "shell.execute_reply": "2025-04-12T03:55:18.515503Z",
     "shell.execute_reply.started": "2025-04-12T03:55:18.508210Z"
    },
    "id": "pending-mother",
    "outputId": "87fb4ed5-6c51-4da4-b208-7a350a170c02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =ts_processor.data_split(ts_processor.dataframe, train_start_date, train_stop_date)       \n",
    "len(train.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "signal-rochester",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:18.517364Z",
     "iopub.status.busy": "2025-04-12T03:55:18.517208Z",
     "iopub.status.idle": "2025-04-12T03:55:18.520952Z",
     "shell.execute_reply": "2025-04-12T03:55:18.520564Z",
     "shell.execute_reply.started": "2025-04-12T03:55:18.517353Z"
    },
    "id": "signal-rochester",
    "outputId": "68104252-5064-4e12-c674-b27b75061fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH',\n",
       "       '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH',\n",
       "       '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d99c321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:18.607655Z",
     "iopub.status.busy": "2025-04-12T03:55:18.607446Z",
     "iopub.status.idle": "2025-04-12T03:55:18.611084Z",
     "shell.execute_reply": "2025-04-12T03:55:18.610581Z",
     "shell.execute_reply.started": "2025-04-12T03:55:18.607639Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.rename(columns={'time': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "future-while",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:19.270038Z",
     "iopub.status.busy": "2025-04-12T03:55:19.269212Z",
     "iopub.status.idle": "2025-04-12T03:55:19.284822Z",
     "shell.execute_reply": "2025-04-12T03:55:19.284119Z",
     "shell.execute_reply.started": "2025-04-12T03:55:19.269998Z"
    },
    "id": "future-while",
    "outputId": "20d6734c-3206-4e18-bab9-ed340dd70151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        date  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "0   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "0  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "0  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "0  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "0  100.000000       20.2000       20.2000  \n",
       "0  100.000000       10.4775       10.4775  \n",
       "0   64.934862        7.0425        7.0425  \n",
       "0  100.000000       35.1925       35.1925  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72e9bcc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:19.945637Z",
     "iopub.status.busy": "2025-04-12T03:55:19.945193Z",
     "iopub.status.idle": "2025-04-12T03:55:19.950163Z",
     "shell.execute_reply": "2025-04-12T03:55:19.949598Z",
     "shell.execute_reply.started": "2025-04-12T03:55:19.945608Z"
    },
    "id": "72e9bcc2",
    "outputId": "2e7dbf8d-4792-4bea-d26d-0fab001dab7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16695, 17)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "provincial-wichita",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:20.774221Z",
     "iopub.status.busy": "2025-04-12T03:55:20.773403Z",
     "iopub.status.idle": "2025-04-12T03:55:20.780751Z",
     "shell.execute_reply": "2025-04-12T03:55:20.779874Z",
     "shell.execute_reply.started": "2025-04-12T03:55:20.774169Z"
    },
    "id": "provincial-wichita",
    "outputId": "81a0dbd5-02d8-4f6a-cfee-62490004bfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 15, State Space: 151\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension*(len(config.INDICATORS)+2)+1\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bbf93",
   "metadata": {
    "id": "e90bbf93"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcb153fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:49.764759Z",
     "iopub.status.busy": "2025-04-12T03:55:49.764030Z",
     "iopub.status.idle": "2025-04-12T03:55:49.774270Z",
     "shell.execute_reply": "2025-04-12T03:55:49.773678Z",
     "shell.execute_reply.started": "2025-04-12T03:55:49.764720Z"
    },
    "id": "dcb153fc"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":False,\n",
    "    # \"initial_buy\":True,\n",
    "    \"hundred_each_trade\":True\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oyat-FppWzZ_",
   "metadata": {
    "id": "oyat-FppWzZ_"
   },
   "source": [
    "## DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "loaded-modem",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:52.453741Z",
     "iopub.status.busy": "2025-04-12T03:55:52.452307Z",
     "iopub.status.idle": "2025-04-12T03:55:52.473578Z",
     "shell.execute_reply": "2025-04-12T03:55:52.472730Z",
     "shell.execute_reply.started": "2025-04-12T03:55:52.453694Z"
    },
    "id": "loaded-modem",
    "outputId": "f6fab15a-ecff-46f1-bcb0-f3750cc751fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "thick-blackjack",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:52.848084Z",
     "iopub.status.busy": "2025-04-12T03:55:52.847197Z",
     "iopub.status.idle": "2025-04-12T03:55:53.501645Z",
     "shell.execute_reply": "2025-04-12T03:55:53.501285Z",
     "shell.execute_reply.started": "2025-04-12T03:55:52.848033Z"
    },
    "id": "thick-blackjack",
    "outputId": "d20ac9f8-f707-4fea-ac04-956270a8bd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\n",
    "                \"batch_size\": 256, \n",
    "               \"buffer_size\": 50000, \n",
    "               \"learning_rate\": 0.0005,\n",
    "               \"action_noise\":\"normal\",\n",
    "                }\n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "growing-supplier",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:55:54.475449Z",
     "iopub.status.busy": "2025-04-12T03:55:54.474036Z",
     "iopub.status.idle": "2025-04-12T03:56:49.178031Z",
     "shell.execute_reply": "2025-04-12T03:56:49.177673Z",
     "shell.execute_reply.started": "2025-04-12T03:55:54.475412Z"
    },
    "id": "growing-supplier",
    "outputId": "7eb00fa2-31d0-4217-8515-fc80db1ebbe9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ddpg/ddpg_2\n",
      "Episode: 2\n",
      "day: 1112, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2233814.01\n",
      "total_reward: 1233814.01\n",
      "total_cost: 12957.99\n",
      "total_trades: 1335\n",
      "Sharpe: 0.799\n",
      "=================================\n",
      "Episode: 3\n",
      "day: 1112, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2721439.89\n",
      "total_reward: 1721439.89\n",
      "total_cost: 107.11\n",
      "total_trades: 44\n",
      "Sharpe: 0.915\n",
      "=================================\n",
      "Episode: 4\n",
      "day: 1112, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2679231.88\n",
      "total_reward: 1679231.88\n",
      "total_cost: 94.12\n",
      "total_trades: 43\n",
      "Sharpe: 0.905\n",
      "=================================\n",
      "Episode: 5\n",
      "day: 1112, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3052953.47\n",
      "total_reward: 2052953.47\n",
      "total_cost: 94.53\n",
      "total_trades: 39\n",
      "Sharpe: 1.003\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 178        |\n",
      "|    time_elapsed    | 24         |\n",
      "|    total_timesteps | 4452       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 254        |\n",
      "|    critic_loss     | 43.3       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 4351       |\n",
      "|    reward          | -0.3052952 |\n",
      "-----------------------------------\n",
      "Episode: 6\n",
      "day: 1112, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2753685.54\n",
      "total_reward: 1753685.54\n",
      "total_cost: 106.46\n",
      "total_trades: 46\n",
      "Sharpe: 0.943\n",
      "=================================\n",
      "Episode: 7\n",
      "day: 1112, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2530152.49\n",
      "total_reward: 1530152.49\n",
      "total_cost: 100.51\n",
      "total_trades: 47\n",
      "Sharpe: 0.867\n",
      "=================================\n",
      "Episode: 8\n",
      "day: 1112, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3344526.59\n",
      "total_reward: 2344526.59\n",
      "total_cost: 94.41\n",
      "total_trades: 37\n",
      "Sharpe: 1.077\n",
      "=================================\n",
      "Episode: 9\n",
      "day: 1112, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2850085.38\n",
      "total_reward: 1850085.38\n",
      "total_cost: 107.62\n",
      "total_trades: 48\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 181        |\n",
      "|    time_elapsed    | 49         |\n",
      "|    total_timesteps | 8904       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 209        |\n",
      "|    critic_loss     | 83.7       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8803       |\n",
      "|    reward          | -0.2849702 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                              tb_log_name='ddpg',\n",
    "                              total_timesteps=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M4QlPuW4XJZ4",
   "metadata": {
    "id": "M4QlPuW4XJZ4"
   },
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "DRWP9owCXK2n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:56:49.179009Z",
     "iopub.status.busy": "2025-04-12T03:56:49.178922Z",
     "iopub.status.idle": "2025-04-12T03:56:49.194712Z",
     "shell.execute_reply": "2025-04-12T03:56:49.194296Z",
     "shell.execute_reply.started": "2025-04-12T03:56:49.179001Z"
    },
    "id": "DRWP9owCXK2n",
    "outputId": "5ebcfede-8048-4d3c-f7d4-9b7c4b02614e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "mGXzLTKiXMBV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T03:56:49.195213Z",
     "iopub.status.busy": "2025-04-12T03:56:49.195125Z",
     "iopub.status.idle": "2025-04-12T03:58:02.186823Z",
     "shell.execute_reply": "2025-04-12T03:58:02.186490Z",
     "shell.execute_reply.started": "2025-04-12T03:56:49.195204Z"
    },
    "id": "mGXzLTKiXMBV",
    "outputId": "833800a5-0bb4-4528-ec79-14a8d7dad8f5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c/a2c_1\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 649         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | -49         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -5.4        |\n",
      "|    reward             | -0.07937996 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.0898      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 666         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | -26.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -1.85       |\n",
      "|    reward             | -0.01864315 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0429      |\n",
      "---------------------------------------\n",
      "Episode: 11\n",
      "day: 1112, episode: 11\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2306512.55\n",
      "total_reward: 1306512.55\n",
      "total_cost: 121045.45\n",
      "total_trades: 11051\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 672         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | -86.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 10.1        |\n",
      "|    reward             | -0.06715155 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 677        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.8      |\n",
      "|    explained_variance | 0.0418     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.325     |\n",
      "|    reward             | -0.1066492 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.0011     |\n",
      "--------------------------------------\n",
      "Episode: 12\n",
      "day: 1112, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1491507.15\n",
      "total_reward: 491507.15\n",
      "total_cost: 86645.85\n",
      "total_trades: 9543\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 679          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -17.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.72        |\n",
      "|    reward             | -0.002387434 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.00781      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 682          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -71.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -1.74        |\n",
      "|    reward             | -0.010444311 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.0921       |\n",
      "----------------------------------------\n",
      "Episode: 13\n",
      "day: 1112, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1270007.10\n",
      "total_reward: 270007.10\n",
      "total_cost: 70154.90\n",
      "total_trades: 8557\n",
      "Sharpe: 0.331\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 683           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.1         |\n",
      "|    explained_variance | -257          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -7.44         |\n",
      "|    reward             | -0.0040090745 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.23          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 684          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -2.53        |\n",
      "|    reward             | -0.010331436 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.0176       |\n",
      "----------------------------------------\n",
      "Episode: 14\n",
      "day: 1112, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1019455.60\n",
      "total_reward: 19455.60\n",
      "total_cost: 88754.40\n",
      "total_trades: 8710\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 684           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.555         |\n",
      "|    reward             | -0.0065674367 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000761      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.7         |\n",
      "|    explained_variance | -4.65         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.723         |\n",
      "|    reward             | -0.0007620636 |\n",
      "|    std                | 1.1           |\n",
      "|    value_loss         | 0.00196       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.402        |\n",
      "|    reward             | -0.011030792 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.000286     |\n",
      "----------------------------------------\n",
      "Episode: 15\n",
      "day: 1112, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 815820.87\n",
      "total_reward: -184179.13\n",
      "total_cost: 61268.13\n",
      "total_trades: 7151\n",
      "Sharpe: -0.188\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.037        |\n",
      "|    reward             | -0.002320423 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 9.26e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0733        |\n",
      "|    reward             | -0.0008254889 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 0.000219      |\n",
      "-----------------------------------------\n",
      "Episode: 16\n",
      "day: 1112, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 928232.20\n",
      "total_reward: -71767.80\n",
      "total_cost: 31925.80\n",
      "total_trades: 4906\n",
      "Sharpe: -0.246\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0306        |\n",
      "|    reward             | -0.0013664213 |\n",
      "|    std                | 1.28          |\n",
      "|    value_loss         | 2.49e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0148       |\n",
      "|    reward             | -0.016323684 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 3.89e-06     |\n",
      "----------------------------------------\n",
      "Episode: 17\n",
      "day: 1112, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1041314.22\n",
      "total_reward: 41314.22\n",
      "total_cost: 20005.78\n",
      "total_trades: 3379\n",
      "Sharpe: 0.271\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 686           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0408       |\n",
      "|    reward             | -0.0023603889 |\n",
      "|    std                | 1.45          |\n",
      "|    value_loss         | 4.93e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 686          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0555      |\n",
      "|    reward             | -0.002668544 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 5.05e-06     |\n",
      "----------------------------------------\n",
      "Episode: 18\n",
      "day: 1112, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1009824.28\n",
      "total_reward: 9824.28\n",
      "total_cost: 17483.72\n",
      "total_trades: 3162\n",
      "Sharpe: 0.067\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 686           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.5         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.924        |\n",
      "|    reward             | -0.0020590222 |\n",
      "|    std                | 1.62          |\n",
      "|    value_loss         | 0.00253       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 686           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | -215          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 1.56          |\n",
      "|    reward             | -0.0008387848 |\n",
      "|    std                | 1.66          |\n",
      "|    value_loss         | 0.00665       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.3         |\n",
      "|    explained_variance | -8.02         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.37          |\n",
      "|    reward             | -0.0022154956 |\n",
      "|    std                | 1.71          |\n",
      "|    value_loss         | 0.000246      |\n",
      "-----------------------------------------\n",
      "Episode: 19\n",
      "day: 1112, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 875138.43\n",
      "total_reward: -124861.57\n",
      "total_cost: 30181.57\n",
      "total_trades: 4252\n",
      "Sharpe: -0.041\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | -0.002837679 |\n",
      "|    std                | 1.79         |\n",
      "|    value_loss         | 5.15e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 687            |\n",
      "|    iterations         | 2200           |\n",
      "|    time_elapsed       | 16             |\n",
      "|    total_timesteps    | 11000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2199           |\n",
      "|    policy_loss        | -0.0216        |\n",
      "|    reward             | -0.00062260707 |\n",
      "|    std                | 1.88           |\n",
      "|    value_loss         | 2.18e-06       |\n",
      "------------------------------------------\n",
      "Episode: 20\n",
      "day: 1112, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 846239.19\n",
      "total_reward: -153760.81\n",
      "total_cost: 29744.81\n",
      "total_trades: 3754\n",
      "Sharpe: -0.895\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | -0.0593       |\n",
      "|    reward             | -0.0001988865 |\n",
      "|    std                | 1.99          |\n",
      "|    value_loss         | 8.05e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.0447       |\n",
      "|    reward             | -0.012557225 |\n",
      "|    std                | 2.11         |\n",
      "|    value_loss         | 3.49e-06     |\n",
      "----------------------------------------\n",
      "Episode: 21\n",
      "day: 1112, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1041574.72\n",
      "total_reward: 41574.72\n",
      "total_cost: 29724.28\n",
      "total_trades: 3835\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.3         |\n",
      "|    explained_variance | 4.17e-06      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | 0.523         |\n",
      "|    reward             | -0.0013057367 |\n",
      "|    std                | 2.22          |\n",
      "|    value_loss         | 0.000314      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | 0.205         |\n",
      "|    reward             | -0.0113130445 |\n",
      "|    std                | 2.32          |\n",
      "|    value_loss         | 5.58e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 22\n",
      "day: 1112, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 992520.39\n",
      "total_reward: -7479.61\n",
      "total_cost: 33876.61\n",
      "total_trades: 4406\n",
      "Sharpe: 0.105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | -0.181        |\n",
      "|    reward             | -0.0008364715 |\n",
      "|    std                | 2.4           |\n",
      "|    value_loss         | 3.81e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 686           |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | -0.127        |\n",
      "|    reward             | -0.0022613693 |\n",
      "|    std                | 2.5           |\n",
      "|    value_loss         | 1.64e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 23\n",
      "day: 1112, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 977089.59\n",
      "total_reward: -22910.41\n",
      "total_cost: 26798.41\n",
      "total_trades: 3993\n",
      "Sharpe: -0.147\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | -0.096       |\n",
      "|    reward             | -0.002254307 |\n",
      "|    std                | 2.63         |\n",
      "|    value_loss         | 8.63e-06     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 687            |\n",
      "|    iterations         | 3000           |\n",
      "|    time_elapsed       | 21             |\n",
      "|    total_timesteps    | 15000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -36.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2999           |\n",
      "|    policy_loss        | 0.277          |\n",
      "|    reward             | -0.00057201245 |\n",
      "|    std                | 2.78           |\n",
      "|    value_loss         | 5.93e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | 0.369         |\n",
      "|    reward             | -0.0038261598 |\n",
      "|    std                | 2.94          |\n",
      "|    value_loss         | 0.000124      |\n",
      "-----------------------------------------\n",
      "Episode: 24\n",
      "day: 1112, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 977122.80\n",
      "total_reward: -22877.20\n",
      "total_cost: 30669.20\n",
      "total_trades: 4470\n",
      "Sharpe: 0.003\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.9        |\n",
      "|    explained_variance | -28.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.317       |\n",
      "|    reward             | -0.007245245 |\n",
      "|    std                | 3.04         |\n",
      "|    value_loss         | 0.00365      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 3300          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 16500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.2         |\n",
      "|    explained_variance | -4.87         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3299          |\n",
      "|    policy_loss        | -3.71         |\n",
      "|    reward             | -0.0030002685 |\n",
      "|    std                | 3.1           |\n",
      "|    value_loss         | 0.011         |\n",
      "-----------------------------------------\n",
      "Episode: 25\n",
      "day: 1112, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696754.04\n",
      "total_reward: -303245.96\n",
      "total_cost: 33400.96\n",
      "total_trades: 4724\n",
      "Sharpe: -0.286\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 686           |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | 0.195         |\n",
      "|    reward             | -0.0001358199 |\n",
      "|    std                | 3.18          |\n",
      "|    value_loss         | 2.89e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39          |\n",
      "|    explained_variance | -0.167       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | -4.6         |\n",
      "|    reward             | -0.001281608 |\n",
      "|    std                | 3.27         |\n",
      "|    value_loss         | 0.0144       |\n",
      "----------------------------------------\n",
      "Episode: 26\n",
      "day: 1112, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 635167.72\n",
      "total_reward: -364832.28\n",
      "total_cost: 26861.28\n",
      "total_trades: 3914\n",
      "Sharpe: -0.599\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | -0.0531       |\n",
      "|    reward             | -0.0031290813 |\n",
      "|    std                | 3.36          |\n",
      "|    value_loss         | 2.6e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.0962       |\n",
      "|    reward             | -0.007308949 |\n",
      "|    std                | 3.49         |\n",
      "|    value_loss         | 9.15e-06     |\n",
      "----------------------------------------\n",
      "Episode: 27\n",
      "day: 1112, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1004895.29\n",
      "total_reward: 4895.29\n",
      "total_cost: 32043.71\n",
      "total_trades: 4411\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | -0.229        |\n",
      "|    reward             | -0.0070000864 |\n",
      "|    std                | 3.65          |\n",
      "|    value_loss         | 3.8e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.0131       |\n",
      "|    reward             | -0.001966166 |\n",
      "|    std                | 3.85         |\n",
      "|    value_loss         | 1.92e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | -0.0499       |\n",
      "|    reward             | -0.0009559276 |\n",
      "|    std                | 4.08          |\n",
      "|    value_loss         | 4.46e-06      |\n",
      "-----------------------------------------\n",
      "Episode: 28\n",
      "day: 1112, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1030865.40\n",
      "total_reward: 30865.40\n",
      "total_cost: 35101.60\n",
      "total_trades: 4751\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.2         |\n",
      "|    explained_variance | -1.14         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | -4.8          |\n",
      "|    reward             | -0.0015587728 |\n",
      "|    std                | 4.31          |\n",
      "|    value_loss         | 0.0142        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.6        |\n",
      "|    explained_variance | -7.7         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -2.36        |\n",
      "|    reward             | -0.002262438 |\n",
      "|    std                | 4.43         |\n",
      "|    value_loss         | 0.00346      |\n",
      "----------------------------------------\n",
      "Episode: 29\n",
      "day: 1112, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 726061.61\n",
      "total_reward: -273938.39\n",
      "total_cost: 32375.39\n",
      "total_trades: 4744\n",
      "Sharpe: -0.335\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4300          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 21500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4299          |\n",
      "|    policy_loss        | 0.232         |\n",
      "|    reward             | -0.0030332394 |\n",
      "|    std                | 4.57          |\n",
      "|    value_loss         | 4.08e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.6         |\n",
      "|    explained_variance | -25.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 0.597         |\n",
      "|    reward             | -0.0007672167 |\n",
      "|    std                | 4.73          |\n",
      "|    value_loss         | 0.000651      |\n",
      "-----------------------------------------\n",
      "Episode: 30\n",
      "day: 1112, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690297.69\n",
      "total_reward: -309702.31\n",
      "total_cost: 33340.31\n",
      "total_trades: 4697\n",
      "Sharpe: -0.487\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 32            |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45           |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | -0.107        |\n",
      "|    reward             | -0.0003815282 |\n",
      "|    std                | 4.88          |\n",
      "|    value_loss         | 1.67e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.5         |\n",
      "|    explained_variance | -0.0849       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | 3.53          |\n",
      "|    reward             | -0.0048436117 |\n",
      "|    std                | 5.02          |\n",
      "|    value_loss         | 0.00654       |\n",
      "-----------------------------------------\n",
      "Episode: 31\n",
      "day: 1112, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 692290.29\n",
      "total_reward: -307709.71\n",
      "total_cost: 36432.71\n",
      "total_trades: 4724\n",
      "Sharpe: -0.420\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 687          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | -0.005559591 |\n",
      "|    std                | 5.17         |\n",
      "|    value_loss         | 3.83e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 687           |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 34            |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | -0.376        |\n",
      "|    reward             | -0.0047419975 |\n",
      "|    std                | 5.38          |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "Episode: 32\n",
      "day: 1112, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1015487.09\n",
      "total_reward: 15487.09\n",
      "total_cost: 41224.91\n",
      "total_trades: 4816\n",
      "Sharpe: 0.117\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 35            |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.0972       |\n",
      "|    reward             | -0.0025603976 |\n",
      "|    std                | 5.61          |\n",
      "|    value_loss         | 6.64e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.9       |\n",
      "|    explained_variance | -0.828      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.296       |\n",
      "|    reward             | -0.00469599 |\n",
      "|    std                | 5.9         |\n",
      "|    value_loss         | 5.75e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | -0.0167      |\n",
      "|    reward             | -0.009469608 |\n",
      "|    std                | 6.12         |\n",
      "|    value_loss         | 2.99e-06     |\n",
      "----------------------------------------\n",
      "Episode: 33\n",
      "day: 1112, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 728993.83\n",
      "total_reward: -271006.17\n",
      "total_cost: 43191.17\n",
      "total_trades: 5183\n",
      "Sharpe: -0.410\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.298       |\n",
      "|    reward             | -0.008276221 |\n",
      "|    std                | 6.38         |\n",
      "|    value_loss         | 5.05e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 5300          |\n",
      "|    time_elapsed       | 38            |\n",
      "|    total_timesteps    | 26500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.8         |\n",
      "|    explained_variance | 0.135         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5299          |\n",
      "|    policy_loss        | -0.77         |\n",
      "|    reward             | -0.0070888903 |\n",
      "|    std                | 6.71          |\n",
      "|    value_loss         | 0.000529      |\n",
      "-----------------------------------------\n",
      "Episode: 34\n",
      "day: 1112, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 827030.33\n",
      "total_reward: -172969.67\n",
      "total_cost: 49630.67\n",
      "total_trades: 5214\n",
      "Sharpe: -0.491\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | -0.0198      |\n",
      "|    reward             | -0.003241285 |\n",
      "|    std                | 7.05         |\n",
      "|    value_loss         | 1.31e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -1.91        |\n",
      "|    reward             | -0.047023967 |\n",
      "|    std                | 7.43         |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "Episode: 35\n",
      "day: 1112, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 927973.53\n",
      "total_reward: -72026.47\n",
      "total_cost: 53242.47\n",
      "total_trades: 5605\n",
      "Sharpe: -0.192\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.345       |\n",
      "|    reward             | -0.004495682 |\n",
      "|    std                | 7.81         |\n",
      "|    value_loss         | 4.53e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -52.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -1.01         |\n",
      "|    reward             | -0.0004936095 |\n",
      "|    std                | 8.17          |\n",
      "|    value_loss         | 0.000367      |\n",
      "-----------------------------------------\n",
      "Episode: 36\n",
      "day: 1112, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 784077.11\n",
      "total_reward: -215922.89\n",
      "total_cost: 58038.89\n",
      "total_trades: 6079\n",
      "Sharpe: -0.269\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.304       |\n",
      "|    reward             | -0.019780941 |\n",
      "|    std                | 8.47         |\n",
      "|    value_loss         | 5.17e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -1.77        |\n",
      "|    reward             | -0.007920344 |\n",
      "|    std                | 8.81         |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.5        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.117       |\n",
      "|    reward             | -0.008322887 |\n",
      "|    std                | 9.19         |\n",
      "|    value_loss         | 1.2e-05      |\n",
      "----------------------------------------\n",
      "Episode: 37\n",
      "day: 1112, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 926827.64\n",
      "total_reward: -73172.36\n",
      "total_cost: 64256.36\n",
      "total_trades: 6167\n",
      "Sharpe: -0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 44            |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.1         |\n",
      "|    explained_variance | -0.131        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | -2.62         |\n",
      "|    reward             | -0.0029157691 |\n",
      "|    std                | 9.62          |\n",
      "|    value_loss         | 0.00356       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 45            |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.5         |\n",
      "|    explained_variance | -9.09         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.0403        |\n",
      "|    reward             | -0.0051775915 |\n",
      "|    std                | 9.87          |\n",
      "|    value_loss         | 4.36e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 38\n",
      "day: 1112, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 705613.96\n",
      "total_reward: -294386.04\n",
      "total_cost: 62633.04\n",
      "total_trades: 6457\n",
      "Sharpe: -0.450\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 6300          |\n",
      "|    time_elapsed       | 45            |\n",
      "|    total_timesteps    | 31500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6299          |\n",
      "|    policy_loss        | 0.25          |\n",
      "|    reward             | -0.0053644883 |\n",
      "|    std                | 10.2          |\n",
      "|    value_loss         | 2.53e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.519        |\n",
      "|    reward             | -0.007434771 |\n",
      "|    std                | 10.6         |\n",
      "|    value_loss         | 9.29e-05     |\n",
      "----------------------------------------\n",
      "Episode: 39\n",
      "day: 1112, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 949297.11\n",
      "total_reward: -50702.89\n",
      "total_cost: 68771.89\n",
      "total_trades: 6709\n",
      "Sharpe: -0.139\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 47            |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | -0.333        |\n",
      "|    reward             | -0.0007678599 |\n",
      "|    std                | 11.1          |\n",
      "|    value_loss         | 9.15e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | 0.43         |\n",
      "|    reward             | -0.005702199 |\n",
      "|    std                | 11.7         |\n",
      "|    value_loss         | 9.04e-05     |\n",
      "----------------------------------------\n",
      "Episode: 40\n",
      "day: 1112, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000687.38\n",
      "total_reward: 687.38\n",
      "total_cost: 72134.62\n",
      "total_trades: 6945\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 48            |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | 0.152         |\n",
      "|    reward             | -0.0065033026 |\n",
      "|    std                | 12.3          |\n",
      "|    value_loss         | 1.56e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.5        |\n",
      "|    explained_variance | -16.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -3.21        |\n",
      "|    reward             | -0.011242629 |\n",
      "|    std                | 12.9         |\n",
      "|    value_loss         | 0.00286      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.1        |\n",
      "|    explained_variance | -18.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 4.19         |\n",
      "|    reward             | -0.013604313 |\n",
      "|    std                | 13.4         |\n",
      "|    value_loss         | 0.00528      |\n",
      "----------------------------------------\n",
      "Episode: 41\n",
      "day: 1112, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 715499.46\n",
      "total_reward: -284500.54\n",
      "total_cost: 74594.54\n",
      "total_trades: 7440\n",
      "Sharpe: -0.463\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 7000          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 35000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -60.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6999          |\n",
      "|    policy_loss        | 0.31          |\n",
      "|    reward             | -0.0023008946 |\n",
      "|    std                | 13.9          |\n",
      "|    value_loss         | 2.94e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -0.0691     |\n",
      "|    reward             | -0.00835693 |\n",
      "|    std                | 14.6        |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "Episode: 42\n",
      "day: 1112, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 985702.51\n",
      "total_reward: -14297.49\n",
      "total_cost: 86013.49\n",
      "total_trades: 7774\n",
      "Sharpe: 0.001\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.00927     |\n",
      "|    reward             | -0.005755292 |\n",
      "|    std                | 15.3         |\n",
      "|    value_loss         | 6.73e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | 0.936         |\n",
      "|    reward             | -0.0037407563 |\n",
      "|    std                | 16.1          |\n",
      "|    value_loss         | 0.000297      |\n",
      "-----------------------------------------\n",
      "Episode: 43\n",
      "day: 1112, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1083529.14\n",
      "total_reward: 83529.14\n",
      "total_cost: 87922.86\n",
      "total_trades: 8102\n",
      "Sharpe: 0.293\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -63.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | 0.366         |\n",
      "|    reward             | -0.0042362306 |\n",
      "|    std                | 16.9          |\n",
      "|    value_loss         | 4.98e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | 0.422       |\n",
      "|    reward             | -0.01019437 |\n",
      "|    std                | 17.8        |\n",
      "|    value_loss         | 6.25e-05    |\n",
      "---------------------------------------\n",
      "Episode: 44\n",
      "day: 1112, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1064256.93\n",
      "total_reward: 64256.93\n",
      "total_cost: 92990.07\n",
      "total_trades: 8514\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 55            |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -64.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | 0.235         |\n",
      "|    reward             | -0.0037536433 |\n",
      "|    std                | 18.5          |\n",
      "|    value_loss         | 2.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.5        |\n",
      "|    explained_variance | -2.06        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.00246      |\n",
      "|    reward             | -0.008630093 |\n",
      "|    std                | 19.4         |\n",
      "|    value_loss         | 3.67e-05     |\n",
      "----------------------------------------\n",
      "Episode: 45\n",
      "day: 1112, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 853539.17\n",
      "total_reward: -146460.83\n",
      "total_cost: 102611.83\n",
      "total_trades: 8839\n",
      "Sharpe: -0.300\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 7800          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 39000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7799          |\n",
      "|    policy_loss        | -0.21         |\n",
      "|    reward             | -0.0046020136 |\n",
      "|    std                | 20.2          |\n",
      "|    value_loss         | 2.1e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 57           |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.6        |\n",
      "|    explained_variance | -1.04        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.899        |\n",
      "|    reward             | -0.010439582 |\n",
      "|    std                | 20.9         |\n",
      "|    value_loss         | 0.000222     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.1        |\n",
      "|    explained_variance | -1.97        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | 0.896        |\n",
      "|    reward             | -0.015878942 |\n",
      "|    std                | 21.6         |\n",
      "|    value_loss         | 0.000203     |\n",
      "----------------------------------------\n",
      "Episode: 46\n",
      "day: 1112, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 818800.43\n",
      "total_reward: -181199.57\n",
      "total_cost: 98887.57\n",
      "total_trades: 8767\n",
      "Sharpe: -0.192\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 684           |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 59            |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | -0.625        |\n",
      "|    reward             | -0.0034125696 |\n",
      "|    std                | 22.3          |\n",
      "|    value_loss         | 9.24e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 684          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | 1.18         |\n",
      "|    reward             | -0.011725396 |\n",
      "|    std                | 23.3         |\n",
      "|    value_loss         | 0.000365     |\n",
      "----------------------------------------\n",
      "Episode: 47\n",
      "day: 1112, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 952991.90\n",
      "total_reward: -47008.10\n",
      "total_cost: 106210.10\n",
      "total_trades: 8963\n",
      "Sharpe: -0.085\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 684          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -1.07        |\n",
      "|    reward             | -0.003590467 |\n",
      "|    std                | 24.3         |\n",
      "|    value_loss         | 0.000401     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 684           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | 0.803         |\n",
      "|    reward             | -0.0104213925 |\n",
      "|    std                | 25.5          |\n",
      "|    value_loss         | 0.000205      |\n",
      "-----------------------------------------\n",
      "Episode: 48\n",
      "day: 1112, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 969850.33\n",
      "total_reward: -30149.67\n",
      "total_cost: 113931.67\n",
      "total_trades: 9298\n",
      "Sharpe: -0.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 684           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -70.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | 0.0119        |\n",
      "|    reward             | -0.0022747454 |\n",
      "|    std                | 26.7          |\n",
      "|    value_loss         | 3.51e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 684          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.9        |\n",
      "|    explained_variance | -44.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | -6.63        |\n",
      "|    reward             | -0.008699917 |\n",
      "|    std                | 28           |\n",
      "|    value_loss         | 0.00982      |\n",
      "----------------------------------------\n",
      "Episode: 49\n",
      "day: 1112, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 672621.27\n",
      "total_reward: -327378.73\n",
      "total_cost: 113308.73\n",
      "total_trades: 9605\n",
      "Sharpe: -0.543\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -1.31        |\n",
      "|    reward             | -0.014696426 |\n",
      "|    std                | 29           |\n",
      "|    value_loss         | 0.000416     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | 0.648        |\n",
      "|    reward             | -0.014148832 |\n",
      "|    std                | 30.2         |\n",
      "|    value_loss         | 9.25e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.4        |\n",
      "|    explained_variance | -76.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 1.7          |\n",
      "|    reward             | -0.012801646 |\n",
      "|    std                | 31           |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "Episode: 50\n",
      "day: 1112, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 859258.08\n",
      "total_reward: -140741.92\n",
      "total_cost: 115194.92\n",
      "total_trades: 9692\n",
      "Sharpe: -0.154\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 65            |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | 0.391         |\n",
      "|    reward             | -0.0138543565 |\n",
      "|    std                | 32.1          |\n",
      "|    value_loss         | 4.53e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.407       |\n",
      "|    reward             | -0.011695492 |\n",
      "|    std                | 33.5         |\n",
      "|    value_loss         | 0.00065      |\n",
      "----------------------------------------\n",
      "Episode: 51\n",
      "day: 1112, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1141094.16\n",
      "total_reward: 141094.16\n",
      "total_cost: 126227.84\n",
      "total_trades: 10293\n",
      "Sharpe: 0.363\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 9200          |\n",
      "|    time_elapsed       | 67            |\n",
      "|    total_timesteps    | 46000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9199          |\n",
      "|    policy_loss        | 0.324         |\n",
      "|    reward             | -0.0025577068 |\n",
      "|    std                | 34.9          |\n",
      "|    value_loss         | 2.72e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 9300          |\n",
      "|    time_elapsed       | 67            |\n",
      "|    total_timesteps    | 46500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9299          |\n",
      "|    policy_loss        | 0.645         |\n",
      "|    reward             | -0.0038446463 |\n",
      "|    std                | 36.5          |\n",
      "|    value_loss         | 9.59e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 52\n",
      "day: 1112, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881157.12\n",
      "total_reward: -118842.88\n",
      "total_cost: 130657.88\n",
      "total_trades: 10422\n",
      "Sharpe: -0.221\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.4        |\n",
      "|    explained_variance | -6.78        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.395       |\n",
      "|    reward             | -0.006997585 |\n",
      "|    std                | 37.9         |\n",
      "|    value_loss         | 6.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.9        |\n",
      "|    explained_variance | -16.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 4.12         |\n",
      "|    reward             | -0.012184357 |\n",
      "|    std                | 39.2         |\n",
      "|    value_loss         | 0.0186       |\n",
      "----------------------------------------\n",
      "Episode: 53\n",
      "day: 1112, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 935953.25\n",
      "total_reward: -64046.75\n",
      "total_cost: 131777.75\n",
      "total_trades: 10616\n",
      "Sharpe: -0.005\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | -0.015       |\n",
      "|    reward             | -0.004939484 |\n",
      "|    std                | 40.5         |\n",
      "|    value_loss         | 5.44e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 685           |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 70            |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -76.9         |\n",
      "|    explained_variance | 0.195         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | 0.848         |\n",
      "|    reward             | -0.0059330775 |\n",
      "|    std                | 42.2          |\n",
      "|    value_loss         | 0.000139      |\n",
      "-----------------------------------------\n",
      "Episode: 54\n",
      "day: 1112, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 818300.48\n",
      "total_reward: -181699.52\n",
      "total_cost: 139538.52\n",
      "total_trades: 11104\n",
      "Sharpe: -0.244\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.886        |\n",
      "|    reward             | -0.015274748 |\n",
      "|    std                | 43.9         |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.1        |\n",
      "|    explained_variance | -2.1         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.811       |\n",
      "|    reward             | -0.014036009 |\n",
      "|    std                | 45.6         |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 685          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.6        |\n",
      "|    explained_variance | 0.0932       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | -0.010851186 |\n",
      "|    std                | 47.1         |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767b826",
   "metadata": {
    "id": "0767b826"
   },
   "source": [
    "### Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "responsible-equity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T03:58:02.188055Z",
     "iopub.status.busy": "2025-04-12T03:58:02.187964Z",
     "iopub.status.idle": "2025-04-12T03:58:02.390087Z",
     "shell.execute_reply": "2025-04-12T03:58:02.389390Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.188046Z"
    },
    "id": "responsible-equity"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/var/folders/95/pdvq31_x4vd63d6hy786f8j00000gn/T/ipykernel_21089/4121704098.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[33m\"print_verbosity\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"initial_buy\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"hundred_each_trade\"\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     15\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
      "\u001b[32m~/Documents/yuty/yuty_projects/money_game/RL/FinRL-Meta/meta/env_stock_trading/env_stocktrading_China_A_shares.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, df, stock_dim, hmax, initial_amount, buy_cost_pct, sell_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, turbulence_threshold, make_plots, print_verbosity, day, initial, previous_state, model_name, mode, iteration, initial_buy, hundred_each_trade)\u001b[39m\n\u001b[32m     77\u001b[39m         self.episode = \u001b[32m0\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[38;5;66;03m# memorize all the total balance change\u001b[39;00m\n\u001b[32m     79\u001b[39m         self.portfolio_memory = []\n\u001b[32m     80\u001b[39m         self.actions_memory = []\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         self.date_memory = [self._get_date()]\n\u001b[32m     82\u001b[39m         self._seed()\n",
      "\u001b[32m~/Documents/yuty/yuty_projects/money_game/RL/FinRL-Meta/meta/env_stock_trading/env_stocktrading_China_A_shares.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_date(self):\n\u001b[32m    432\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(self.df.tic.unique()) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m             date = self.data.date.unique()[\u001b[32m0\u001b[39m]\n\u001b[32m    434\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m             date = self.data.date\n\u001b[32m    436\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m date\n",
      "\u001b[32m/opt/anaconda3/envs/finrl/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6295\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6296\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m         ):\n\u001b[32m   6298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "trade = ts_processor.data_split(ts_processor.dataframe, val_start_date, val_stop_date)\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":False,\n",
    "    \"hundred_each_trade\":True\n",
    "}\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-hierarchy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.390273Z",
     "iopub.status.idle": "2025-04-12T03:58:02.390383Z",
     "shell.execute_reply": "2025-04-12T03:58:02.390326Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.390321Z"
    },
    "id": "first-hierarchy",
    "outputId": "2e8d17c8-11ba-47ce-a938-93ae7f21f3bb"
   },
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
    "                       environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d6c2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.390916Z",
     "iopub.status.idle": "2025-04-12T03:58:02.391085Z",
     "shell.execute_reply": "2025-04-12T03:58:02.390998Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.390993Z"
    },
    "id": "8b9d6c2b",
    "outputId": "3bee87a7-ec13-4b20-9698-040a8e3ecd4b"
   },
   "outputs": [],
   "source": [
    "df_actions.to_csv(\"action.csv\",index=False)\n",
    "df_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8a81c",
   "metadata": {
    "id": "6ea8a81c"
   },
   "source": [
    "### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d62e0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.391911Z",
     "iopub.status.idle": "2025-04-12T03:58:02.392048Z",
     "shell.execute_reply": "2025-04-12T03:58:02.391979Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.391974Z"
    },
    "id": "727d62e0"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "plotter = ReturnPlotter(df_account_value, trade, val_start_date, val_stop_date)\n",
    "# plotter.plot_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813f87d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.392624Z",
     "iopub.status.idle": "2025-04-12T03:58:02.392751Z",
     "shell.execute_reply": "2025-04-12T03:58:02.392676Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.392672Z"
    },
    "id": "8813f87d",
    "outputId": "f36bca9c-b211-48dc-8350-2b8f34a35767"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155bcd5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.393590Z",
     "iopub.status.idle": "2025-04-12T03:58:02.393709Z",
     "shell.execute_reply": "2025-04-12T03:58:02.393651Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.393646Z"
    },
    "id": "d155bcd5"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# # ticket: SSE 50：000016\n",
    "# plotter.plot(\"000016\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce724f71",
   "metadata": {
    "id": "ce724f71"
   },
   "source": [
    "#### Use pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c82f77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.394462Z",
     "iopub.status.idle": "2025-04-12T03:58:02.394768Z",
     "shell.execute_reply": "2025-04-12T03:58:02.394663Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.394653Z"
    },
    "id": "79c82f77",
    "outputId": "af7814b3-cabd-4ee1-a6c9-ab64befd9458"
   },
   "outputs": [],
   "source": [
    "# CSI 300\n",
    "baseline_df = plotter.get_baseline(\"399300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab0438",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.395214Z",
     "iopub.status.idle": "2025-04-12T03:58:02.395391Z",
     "shell.execute_reply": "2025-04-12T03:58:02.395275Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.395270Z"
    },
    "id": "e4ab0438",
    "outputId": "312eccd8-4a3b-4589-f155-de24e0162280"
   },
   "outputs": [],
   "source": [
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return, \n",
    "                              factor_returns=daily_return_base, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8jnvuVBdWV9r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.395917Z",
     "iopub.status.idle": "2025-04-12T03:58:02.396083Z",
     "shell.execute_reply": "2025-04-12T03:58:02.395997Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.395991Z"
    },
    "id": "8jnvuVBdWV9r",
    "outputId": "6cfd45d6-fe38-412f-eb81-11b300134c56"
   },
   "outputs": [],
   "source": [
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return_base, \n",
    "                              factor_returns=daily_return_base, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============Baseline Strategy Stats===========\")\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215cc99",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-12T03:58:02.396807Z",
     "iopub.status.idle": "2025-04-12T03:58:02.396924Z",
     "shell.execute_reply": "2025-04-12T03:58:02.396857Z",
     "shell.execute_reply.started": "2025-04-12T03:58:02.396852Z"
    },
    "id": "8215cc99"
   },
   "outputs": [],
   "source": [
    "# with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "#         pyfolio.create_full_tear_sheet(returns = daily_return,\n",
    "#                                        benchmark_rets = daily_return_base, set_context=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11979d",
   "metadata": {
    "id": "ce11979d"
   },
   "source": [
    "### Authors\n",
    "github username: oliverwang15, eitin-infant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d02fcc-ce4d-4218-927d-754284c05d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5884d-f090-4c29-95b9-aac6b823726c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13902f-9c01-4582-8fa2-a130917e095e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Demo_China_A_share_market.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
